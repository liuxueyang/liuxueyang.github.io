<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>重新整理博客 &middot; liuxueyang</title>

  
  <link rel="stylesheet" href="http://liuxueyang.github.io/css/poole.css">
  <link rel="stylesheet" href="http://liuxueyang.github.io/css/hyde.css">
  <link rel="stylesheet" href="http://liuxueyang.github.io/css/poole-overrides.css">
  <link rel="stylesheet" href="http://liuxueyang.github.io/css/hyde-overrides.css">
  <link rel="stylesheet" href="http://liuxueyang.github.io/css/hyde-x.css">
  <link rel="stylesheet" href="http://liuxueyang.github.io/css/highlight/sunburst.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://liuxueyang.github.io/touch-icon-144-precomposed.png">
  <link href="http://liuxueyang.github.io/favicon.png" rel="icon">

  
  
  
  

  <meta name="description" content="This is my Notes">
  <meta name="keywords" content="Notes,Diary">
  
</head>
<body class="theme-base-08">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      
        <img src="https://www.gravatar.com/avatar/64a07d5d65356951681329b9d0f81285?s=200"
             alt="gravatar" title="liuxueyang">
      
      <h1>liuxueyang</h1>
      <p class="lead">THE LAST ONE.</p>
    </div>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item"><a href="http://liuxueyang.github.io/">Blog</a></li>
      
    </ul>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <a href="http://github.com/liuxueyang"><i class="fa fa-github-square fa-3x"></i></a>
      
      
      
      
      
      
      
      
      </li>
    </ul>

    

    <p>Copyright &copy; 2017 <a href="http://liuxueyang.github.io/license/">License</a><br/>
       Powered by <a href="http://gohugo.io">Hugo</a> and <a href="https://github.com/zyro/hyde-x">Hyde-X</a></p>
  </div>
</div>


<div class="content container">
  <div class="post">
    <h1 class="post-title">重新整理博客</h1>
    <span class="post-date">Apr 10, 2017 &middot; 2 minute read &middot; <a href="http://liuxueyang.github.io/blog/2017/04/10/%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E5%8D%9A%E5%AE%A2/#disqus_thread">Comments</a>
    </span>
    <p>这么长时间过去了，好像很久不管这个博客了，差不多10个月过去了。是时候
把这些零散的东西整理一下了。争取把之前在别的地方写的东西都整理到这里
来。这样以后查看会方便很多吧！</p>

<p>主要是2014年的「博客园」上面的东西。找了一下现有的工具<a href="https://npm.taobao.org/package/hexo-migrator-cnblogs">hexo-migrator-cnblogs</a>发现早已经不维护了，现在也不能用了。所以写了一个简单的脚本来爬取我的博客：</p>

<pre><code class="language-python"># 2017/04/11 00:45:15 AM
# Author: liuxueyang

from bs4 import BeautifulSoup
import requests
import re
import os.path

url = 'http://www.cnblogs.com/liuxueyang/default.html?page='
page_nums = range(1, 11)
cnt = 0
already_urls = []

if os.path.exists('already.txt'):
    with open('already.txt', 'r') as already_f:
        already_urls = already_urls + already_f.readlines()

for page_num in page_nums:
    url1 = url + str(page_num)
    r = requests.get(url1)
    soup = BeautifulSoup(r.content, 'html5lib')

    titles = soup.find_all('a', class_='posttitle')
    for title in titles:
        print '==' * 20, '\n\n'
        cnt += 1
        blog_url = title.get('href')
        blog_name = title.string
        blog_r = requests.get(blog_url)

        if blog_url + '\n' in already_urls:
            print cnt, blog_name
            continue

        blog_soup = BeautifulSoup(blog_r.content, 'html5lib')
        blog_body = blog_soup.find(id='cnblogs_post_body')
        blog_date = blog_soup.find(id='post-date').text

        print cnt, blog_url
        tags = 'tags: \n'

        body = [
            '---\n', 'title: &quot;%s&quot;\n' % blog_name, 'date: %s\n' % blog_date,
            tags, '---\n\n'
        ]

        for child in blog_body.children:
            if child.name == 'p':
                body.append(child.text + '\n')
            elif child.name == 'div' and child.has_attr('class') and child.get(
                    'class')[0] == 'cnblogs_code':
                lines = child.text.split('\n')
                body.append('\n```cpp\n')
                for line in lines:
                    line = re.sub(r'^ *', '', line)
                    line = re.sub(r'^\d* ', '', line)
                    body.append(line + '\n')
                body.append('```\n\n')

        for line in body:
            print line,
        file_name = re.sub(r' |/', '-', blog_name) + '.md'
        print file_name

        action = raw_input()

        if action == 'S':
            process_later_file = 'later.txt'
            f = open(process_later_file, 'a')
            f.write(blog_url + '\n')
            print '-' * 30
            print 'process by hand later!'
            print '-' * 30
            f.close()
            continue

        if action:
            action = action.split(',')
            tags = 'tags: [' + ', '.join(action) + ']' + '\n'
            body[3] = tags

        ff = open(file_name, 'w')
        for b in body:
            ff.write(b.encode('utf-8'))
        ff.close()

        with open('already.txt', 'a') as already_f:
            already_f.write(blog_url + '\n')

</code></pre>

<p>没有加处理图片的功能。因为以前的博客用的图片并不多，手动处理。它会抓取博客正文和嵌入的代码，处理嵌入代码的时候花了比较多的时间，比如如果从xml中获取到嵌入的代码，然后去掉行号之类的。这个程序抓取到一篇博客就显示出博客正文和代码块来，等待用户输入，如果正常，之间按回车处理下一篇，如果原来的博客有图片或者抓取的内容不完整，按下<code>S</code>会把当前博客的地址保存到一个<code>later.txt</code>这个文本文件里，随后手动处理。已经处理好的博客地址放到<code>already.txt</code>文件里，这样避免了重复处理。结果还可以。</p>

<p>总共有455篇日志了。可能是我的电脑太老的原因，hexo生成的时候竟然用了好几分钟。所以之后想试一试Hakyll了。</p>

  </div>
  <div id="disqus_thread"></div>
</div>


<script type="text/javascript">
var disqus_shortname = "abeliu";
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>



<script type="text/javascript">
    var disqus_shortname = "abeliu";
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

<script src="http://liuxueyang.github.io/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</body>
</html>

